= LVM <3
Guillaume Coré (fridim)
:icons: font
:toc2:
:source-highlighter: coderay
:description: LVM captain's log
:keywords: lvm

Il m’arrive encore de m’extasier sur des acquis de longue date.
Aujourd’hui c’est LVM : c’est simple, solide, ça fonctionne, et ça rend
bien service!

Ma configuration actuelle comporte :

* `/dev/md0`: 2 disques de 1To en RAID 1 md logiciel
* LVM avec cet array comme PV

Je suis content sauf que pour le raid1, j’ai utilisé les disques en
entier directement plutôt que 2 partitions. Les disques étant exactement
de même taille et modèle, ça n’a jamais posé de souci. Mais cela risque
d’en poser un le jour où je dois changer un des disques pour un autre
dont la capacité exacte me sera inconnue.

Lors de la création de la partition RAID, laisser une marge de 100M à la
fin du disque évite d’avoir des soucis lorsqu’il faut changer un disque.

J’ai donc décidé de reconstruire mon raid avec des partitions. En plus
c’est vendredi! Et parce que sinon c’est pas drôle, je le fais sans
disque supplémentaire, ni backup. J’aurais aussi bien pu titrer « How to
lose all your data in one day! ». Bon tanpis, on se lance :)

== Le plan de bataille

* casser le raid des disques A et B en enlevant un disque, disons B
* ajouter B comme PV du VG
* évacuer tous les physical extents (PE) de l’array (qui ne contient
plus que A) sur B (durée: ~3h)
* supprimer l’array des PVs
* désassembler l’array
* formatter A comme il faut
* recréer l’array avec la partition de A
* mettre l’array (qui n’a que A pour l’instant) dans le VG
* évacuer tous les physical extents de B vers l’array (durée: ~3h)
* supprimer B des PVs
* formatter B comme il faut
* ajouter la partition de B dans l’array (durée sync: ~3h)

On est pas bien là ? Aucun souci, aucun risque! :P

J’ai complété après-coup en ajoutant la durée pour certaines opérations
longues. Cela dépend évidemment de la taille et des performances des
disques mais ça peut donner une idée.

== Leçons apprises

Bien wipe le début du disque qu’on retire du array car sinon LVM se
plaint d’avoir des PV dupliqués trouvés.

WARNING: *RTFM* bien vérifier les options entre `sfdisk` et `sgdisk`. Ex:
`sfdisk -d` c’est pour dump, `sgdisk -d` c’est pour `--delete`. C’est
complétement contre-intuitif, mais tout le monde regarde le man avant de
faire quelque chose d’idiot non ?

== All in!

[source,shell]
....
mdadm --fail /dev/md0 /dev/sda
mdadm --remove /dev/md0 /dev/sda
mdadm --zero-superblock /dev/sda
pvcreate /dev/sda
vgextend vg0 /dev/sda
pvmove /dev/md0   #start: 11:05   finish: 14:15   ~3h
vgreduce vg0 /dev/md0
mdadm --stop /dev/md0
mdadm --remove /dev/md0
mdadm --zero-superblock /dev/sdb
gdisk  /dev/sdb
# partition type FD00 hex code
partprobe

mdadm --create --verbose --level=1 --metadata=1.2 --raid-devices=2 /dev/md0 /dev/sdb1 missing
mdadm --detail --scan >> /etc/mdadm.conf
mdadm --assemble --scan

pvcreate /dev/md0
vgextend vg0 /dev/md0
pvmove /dev/sda
vgreduce vg0 /dev/sda

sgdisk /dev/sdb -R /dev/sda
sgdisk -G /dev/sda
partprobe
mdadm --add /dev/md0 /dev/sda1

grub-mkconfig
grub-install /dev/sda
....

== Conclusion

Je suis content d’avoir bien noté et décrit toutes les étapes (dans le
détail, important) avant de me lancer. Ça permet de valider que c’est
faisable, de faire ressortir les incohérences aussi. Et puis c’est bien
de ne pas perdre trop de temps lorsqu’on est sur une seule patte à
utiliser les disques à fond.

En pratique, je n’ai eu *AUCUN* souci, bonne surprise! Quelques petites
choses ont été ajoutées/modifées a posteriori, et elles sont toutes (les
deux) dans « Leçons apprises ».

== Liens

* https://wiki.archlinux.org/index.php/RAID
* link:20170505-lvm.adoc[]

++++
include::../inc/disqus.html[]
++++
